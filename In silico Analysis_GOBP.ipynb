{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4418cfc7-dce9-45a1-a7ff-12ff3442fd14",
   "metadata": {},
   "source": [
    "## Import libraries and define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfe86b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import configparser\n",
    "import psycopg2\n",
    "import os\n",
    "import ast\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import networkx as nx\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import datetime\n",
    "import csv\n",
    "import statistics\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "from statistics import harmonic_mean\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# Return the arithmetic mean of a list of numbers.\n",
    "def calculate_mean(numbers):\n",
    "    return sum(numbers) / len(numbers)\n",
    "\n",
    "# Return the sample standard deviation of a list of numbers.\n",
    "def calculate_standard_deviation(numbers):\n",
    "    return statistics.stdev(numbers)\n",
    "\n",
    "# Merge multiple RWR score lists and compute a harmonic mean per gene.\n",
    "def combine_lists(full_list):\n",
    "    combined = defaultdict(list)\n",
    "    \n",
    "    for sublist in full_list:\n",
    "        for item in sublist:\n",
    "            entrez_id, rwr_score = item\n",
    "            combined[entrez_id].append(rwr_score)\n",
    "    \n",
    "    result = []\n",
    "    for entrez_id, scores in combined.items():\n",
    "        if len(scores) == 1:\n",
    "            result.append([entrez_id, scores[0]])\n",
    "        else:\n",
    "            harmonic_mean_score = harmonic_mean(scores)\n",
    "            result.append([entrez_id, harmonic_mean_score])\n",
    "    \n",
    "    return result\n",
    "\n",
    "def compound_target(compoundid):\n",
    "    \n",
    "    compound_gene1=conn_cur.fetchall()\n",
    "\n",
    "    compound_gene=set(compound_gene1)\n",
    "    compound_gene=list(compound_gene)\n",
    "    \n",
    "    direct_target_gene = [] \n",
    "    for i in range(len(compound_gene)):\n",
    "        interaction_gene = compound_gene[i][0]\n",
    "        if interaction_gene in entrez_list:\n",
    "            direct_target_gene.append(interaction_gene)        \n",
    "        else:\n",
    "            continue\n",
    "\n",
    "    direct_seed_node = [] \n",
    "    for entrez in direct_target_gene:\n",
    "        node_ = node_index.get(entrez) \n",
    "        direct_seed_node.append(node_)\n",
    "    \n",
    "    num1=len(direct_target_gene) \n",
    "    \n",
    "    var_name1 = f'{compoundid}_num1'\n",
    "\n",
    "    globals()[var_name1] = num1\n",
    "\n",
    "    return direct_target_gene\n",
    "\n",
    "# Run RWR after sampling random genes equal in count to real targets.\n",
    "def rwr_compound_target(count,entrez_list):\n",
    "    \n",
    "    num1=directed_target_gene_count_list[count]\n",
    "    \n",
    "    random_interaction_gene1 = random.sample(entrez_list, num1)\n",
    "\n",
    "    direct_seed_node = [] \n",
    "    for entrez in random_interaction_gene1:\n",
    "        node_ = node_index.get(entrez)\n",
    "        direct_seed_node.append(node_)\n",
    "\n",
    "    initialized = RWR_initializing(G, seed_nodes=direct_seed_node, is_weighted=False) \n",
    "    \n",
    "    rwr=RWR(initialized=initialized, prob=0.25, max_iter=100, tol=1.0e-6)\n",
    "    rwr_mapping_entrez = [[entrez_list[i], rwr[node_index.get(entrez_list[i])]] for i in range(len(entrez_list))]\n",
    "    return rwr_mapping_entrez\n",
    "\n",
    "# Build an undirected PPI graph and a node-to-index dictionary.\n",
    "def create_ppi_network(network_data):\n",
    "    network_data = network_data.astype({'Entrez Gene Interactor A': str,\n",
    "                                        'Entrez Gene Interactor B': str})\n",
    "\n",
    "    symbolA = network_data.loc[:, 'Entrez Gene Interactor A'].to_list()\n",
    "    symbolB = network_data.loc[:, 'Entrez Gene Interactor B'].to_list()\n",
    "\n",
    "    symbol_list = symbolA + symbolB \n",
    "    symbol_list = set(symbol_list) \n",
    "    symbol_list = list(symbol_list)\n",
    "\n",
    "    node_index = {}\n",
    "    for i in range(len(symbol_list)):\n",
    "        node_index[symbol_list[i]] = i\n",
    "\n",
    "    node_list = node_index.values()\n",
    "    \n",
    "    edge_list = network_data[['Entrez Gene Interactor A', 'Entrez Gene Interactor B']].values.tolist()\n",
    "    for i in range(len(edge_list)):\n",
    "        edge_list[i][0] = node_index.get(edge_list[i][0])\n",
    "        edge_list[i][1] = node_index.get(edge_list[i][1])\n",
    "    \n",
    "    G = nx.Graph()\n",
    "    G.add_nodes_from(node_list)\n",
    "    G.add_edges_from(edge_list)\n",
    "\n",
    "    print(f'Number of created nodes: {G.number_of_nodes()}')\n",
    "    print(f'Number of created edges: {G.number_of_edges()}')\n",
    "\n",
    "    return G, node_index\n",
    "\n",
    "# Prepare normalized adjacency matrix and initial vectors for RWR.\n",
    "def RWR_initializing(G, seed_nodes, is_weighted=False):\n",
    "    norm_A = np.zeros(shape=(len(G), len(G)))\n",
    "    if is_weighted:  \n",
    "        for i, neighbor_dict in G.adjacency():\n",
    "            for j, v in neighbor_dict.items():\n",
    "                norm_A[i][j] = v.get(\"weight\", 1 / len(neighbor_dict))\n",
    "    else:  \n",
    "        for i, neighbor_dict in G.adjacency():  \n",
    "            for j, v in neighbor_dict.items():  \n",
    "                norm_A[i][j] = 1 / len(neighbor_dict)\n",
    "    \n",
    "    personalization = {node: 1 for node in seed_nodes}\n",
    "        \n",
    "    r_0 = np.array([personalization.get(n, 0) for n in range(len(G))]) \n",
    "    r_c = np.repeat(1 / len(G), len(G)) \n",
    "    return {\"norm_A\": norm_A, \"r_0\": r_0, \"r_c\": r_c, \"N\": len(G)}\n",
    "\n",
    "# Perform Random Walk with Restart until convergence or max_iter.\n",
    "def RWR(initialized, prob=0.25, max_iter=100, tol=1.0e-6):\n",
    "    if initialized is None:\n",
    "        raise ValueError('initialized information must be required')\n",
    "\n",
    "    norm_A = initialized['norm_A']  \n",
    "    r_0 = initialized['r_0']        \n",
    "    r_c = initialized['r_c']     \n",
    "    N = initialized['N']           \n",
    "    for iteration in range(max_iter):\n",
    "        r_prev = r_c\n",
    "        r_c = prob * r_c @ norm_A + (1 - prob) * r_0 \n",
    "        err = np.absolute(r_c - r_prev).sum()\n",
    "        if err < N * tol:\n",
    "            return r_c\n",
    "    return \"NotConverged\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a69cd481",
   "metadata": {},
   "outputs": [],
   "source": [
    "network_data = pd.read_csv(\"Dataset/BIOGRID-ORGANISM-Homo_sapiens-4.4.228, 9606-9606.csv\", encoding=\"cp949\")\n",
    "G, node_index = create_ppi_network(network_data=network_data)  \n",
    "entrez_list = list(node_index.keys())\n",
    "\n",
    "gene_phenotype_file = 'Dataset/ENTREZ_GENE_ID2GOTERM_BP_DIRECT_2.csv'\n",
    "if os.path.isfile(gene_phenotype_file): \n",
    "    gene_phenotype_df = pd.read_csv(gene_phenotype_file, encoding='UTF-8', converters={'Phenotype': ast.literal_eval}) \n",
    "\n",
    "phenotype_list = []\n",
    "for phen_list in gene_phenotype_df['Phenotype']:\n",
    "    for phen in phen_list:\n",
    "        if phen not in phenotype_list:\n",
    "            phenotype_list.append(phen)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ff8bd1-e89d-49fa-b2b7-48f1566fc398",
   "metadata": {},
   "source": [
    "## Define Compound groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbbd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "number=1\n",
    "compound_text=[]\n",
    "text=[\"adenine\", \"canavanin\", \"malate\", \"isoleucine\", \"phenylalanine\", \"tyrosine\", \"isocitrate\", \"glutamine\", \"tryptophan\",\"L-malate\", \n",
    "      \"theogallin\", \"trans-aconitate\", \"cis-aconitate\", \"threonate\", \"benzoic acid\", \"choline\", \"citric acid\", \"coumarin\", \"phloroglucinol\", \"gallic acid\", \n",
    "      \"citrullin\", \"pipecolic acid\", \"vitamin B\", \"pantothenic acid\", \"DL-valine\", \"vanillin\", \"theophylline\", \"caffeine\", \"protocatechuic aldehyde\", \"adenosine\", \n",
    "      \"EGCG\", \"gallocatechin\", \"N-acetylglutamate\", \"loliolide\", \"procyanidin B2\", \"3H-proline\", \"dihydromyricetin\", \"beta-alanine betaine\", \"epicatechin gallate (ECG\", \"5'-methylthioadenosine\", \n",
    "      \"epiafzelechin\", \"ferulic acid\", \"p-coumaric acid\", \"caffeic acid\", \"chlorogenic acid\", \"quercetin\", \"alpha-isopropylmalate\", \"neochlorogenic acid\", \"rutin\", \"hyperoside\", \n",
    "      \"4-p-coumaroylquinic acid\", \"astragalin\", \"quercetin 7-O-glucoside\", \"p-coumaroylquinic acid\", \"procyanidin B1\"]\n",
    "compound_text.append(text)\n",
    "\n",
    "number=2\n",
    "text=[\"gamma-aminobutyric acid (GABA\", \"canavanin\", \"sucrose\", \"folate\", \"guanosine\", \"vanillic acid\", \"ononin\", \n",
    "      \"formononetin\", \"calycosin\", \"sissotrin\", \"afrormosin\", \"pratensein\"]\n",
    "compound_text.append(text)\n",
    "\n",
    "number=3\n",
    "text=[\"protocatechuic acid\", \"gamma-aminobutyric acid (GABA\", \"choline\", \"citric acid\", \"malate\", \"asparagine\", \n",
    "      \"quinic acid\", \"maltol\", \"nodakenetin\", \"nodakenin\", \"columbianetin\", \"decursin\", \"ferulic acid\", \"caffeic acid\",\n",
    "      \"aegelinol\", \"cis-chlorogenic acid\", \"chlorogenic acid\", \"esculetin\"]\n",
    "compound_text.append(text)\n",
    "\n",
    "number=4\n",
    "text=[\"piperine\", \"piperanine\", \"piperlonguminine\", \"retrofractamide B\", \"dehydropipernonaline\", \"Methyl piperate\", \"pipernonaline\", \"Retrofractamide A\", \"retrofractamide C\"]\n",
    "compound_text.append(text)\n",
    "\n",
    "number=5\n",
    "text=[\"apocynin\", \"resacetophenone\", \"4-hydroxyacetophenone\", \"2,5-dihydroxyacetophenone\", \"physcion\"]\n",
    "compound_text.append(text)\n",
    "\n",
    "number=6\n",
    "text=[\"protocatechuic acid\", \"p-hydroxybenzaldehyde\", \"choline\", \"gluconate\", \"myo-inositol\", \"thymine\", \"uracil\", \"vanillin\", \"vanillic acid\", \"protocatechuic aldehyde\", \"trans-aconitate\", \"ferulic acid\", \"caffeic acid\", \"chlorogenic acid\", \"linoleic acid\", \"neochlorogenic acid\", \"xanthatin\", \"cynarin\", \"cynarine\"]\n",
    "compound_text.append(text)\n",
    "\n",
    "number=7\n",
    "text=[\"atractylenolide III\", \"vanillic acid\", \"esculetin\", \"elemicin\", \"adenosine\"]\n",
    "compound_text.append(text)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8f0b69-c057-4310-b22b-92f5be61537c",
   "metadata": {},
   "source": [
    "## Quantifying Compound Effects through Random Walk with Restart and Pathway Score Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66486f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "number=0\n",
    "for text in compound_text:\n",
    "    number=number+1\n",
    "    print(number,\"_Compound group\")\n",
    "    Compoundid_list=[]\n",
    "    for compound in text:\n",
    "\n",
    "        result = conn_cur.fetchone()\n",
    "        if result:\n",
    "            Compoundid_list.append(result[0])\n",
    "        else:\n",
    "            Compoundid_list.append(None)  # Append None when the compound ID is not found\n",
    "\n",
    "    if not os.path.exists('Results/Direct_GOBP/Compound group_{}'.format(number)):\n",
    "        os.makedirs('Results/Direct_GOBP/Compound group_{}'.format(number)) \n",
    "\n",
    "    Compound_list=copy.deepcopy(Compoundid_list)\n",
    "\n",
    "    global directed_target_gene_count_list\n",
    "    directed_target_gene_count_list=[]  # List storing the number of direct target genes for each input compound\n",
    "\n",
    "    direct_target_gene_list=[] # Direct target genes for each compound\n",
    "\n",
    "    for c in range(len(Compound_list)):\n",
    "\n",
    "        compoundid1=Compound_list[c]\n",
    "\n",
    "        direct_output_list= compound_target(compoundid1)\n",
    "        \n",
    "        direct_target_gene_list=direct_target_gene_list+direct_output_list\n",
    "\n",
    "    direct_target_gene_list=set(direct_target_gene_list)\n",
    "    direct_target_gene_list=list(direct_target_gene_list)\n",
    "\n",
    "    direct_seed_node = [] \n",
    "    for entrez in direct_target_gene_list:\n",
    "        node_ = node_index.get(entrez) \n",
    "        direct_seed_node.append(node_)\n",
    "    \n",
    "    num1=len(direct_target_gene_list) \n",
    "    directed_target_gene_count_list.append(num1)\n",
    "    print(\"Number of direct target genes \",num1)    \n",
    "    \n",
    "    initialized = RWR_initializing(G, seed_nodes=direct_seed_node, is_weighted=False) \n",
    "\n",
    "    rwr = RWR(initialized=initialized, prob=0.25, max_iter=100, tol=1.0e-6)\n",
    "    rwr_mapping_entrez = [[entrez_list[i], rwr[node_index.get(entrez_list[i])]] for i in range(len(entrez_list))]\n",
    "\n",
    "    rwr_result = pd.DataFrame(data=rwr_mapping_entrez, columns=['Entrez ID', 'RWR_score'])\n",
    "    rwr_result['Entrez ID'] = rwr_result['Entrez ID'].astype(int)\n",
    "    rwr_result = pd.merge(rwr_result, gene_phenotype_df, how='outer')\n",
    "    rwr_result = rwr_result.dropna(subset=['RWR_score'])\n",
    "    rwr_result['Phenotype'].loc[rwr_result['Phenotype'].isnull()] = rwr_result['Phenotype'].loc[\n",
    "        rwr_result['Phenotype'].isnull()].apply(lambda x: [])\n",
    "    rwr_result = rwr_result.sort_values(by='RWR_score', ascending=False)\n",
    "\n",
    "    phenotype_rwr_score_dict = {}\n",
    "    for phen in phenotype_list:\n",
    "        phenotype_rwr_score_dict[phen] = 0    \n",
    "\n",
    "    for i in range(len(rwr_result)):\n",
    "        rwr_score = rwr_result['RWR_score'].iloc[i]\n",
    "        if rwr_result['Phenotype'].iloc[i]:\n",
    "            for phen in rwr_result['Phenotype'].iloc[i]:\n",
    "                phenotype_rwr_score_dict[phen] += rwr_score\n",
    "\n",
    "    temp=list(phenotype_rwr_score_dict.keys())\n",
    "    for i in temp:\n",
    "        if np.isnan(phenotype_rwr_score_dict[i])==True:\n",
    "            phenotype_rwr_score_dict.pop(i)\n",
    "\n",
    "    Phenotype_score_Phenotype=list(phenotype_rwr_score_dict.keys())\n",
    "    Phenotype_score_Score=list(phenotype_rwr_score_dict.values())\n",
    "\n",
    "    # Save phenotype scores\n",
    "    inferred_phenotype2 = pd.DataFrame(data=[pair for pair in zip(list(phenotype_rwr_score_dict.keys()),\n",
    "                                                                 list(phenotype_rwr_score_dict.values()))],\n",
    "                                      columns=['Phenotype', 'Network_score'])\n",
    "    inferred_phenotype2 = inferred_phenotype2.sort_values(by='Network_score', ascending=False)\n",
    "    inferred_phenotype2.to_csv('Results/Direct_GOBP/Compound group_{}/{}_phenotype_score.csv'.format(number,number),index=False, encoding='UTF-8')\n",
    "\n",
    "    output_dict={}\n",
    "    #----------------------------------------------------------------Statistical Tests\n",
    "    for h in tqdm_notebook(range(1000)):\n",
    "        random_interaction_gene1 = random.sample(entrez_list, num1)\n",
    "        \n",
    "        direct_seed_node = [] \n",
    "        for entrez in random_interaction_gene1:\n",
    "            node_ = node_index.get(entrez)\n",
    "            direct_seed_node.append(node_)\n",
    "    \n",
    "        initialized = RWR_initializing(G, seed_nodes=direct_seed_node, is_weighted=False) \n",
    "    \n",
    "        rwr=RWR(initialized=initialized, prob=0.25, max_iter=100, tol=1.0e-6)\n",
    "        rwr_mapping_entrez = [[entrez_list[i], rwr[node_index.get(entrez_list[i])]] for i in range(len(entrez_list))]\n",
    "\n",
    "        rwr_result = pd.DataFrame(data=rwr_mapping_entrez, columns=['Entrez ID', 'RWR_score'])\n",
    "        rwr_result['Entrez ID'] = rwr_result['Entrez ID'].astype(int)\n",
    "        rwr_result = pd.merge(rwr_result, gene_phenotype_df, how='outer')\n",
    "        rwr_result = rwr_result.dropna(subset=['RWR_score'])\n",
    "        rwr_result['Phenotype'].loc[rwr_result['Phenotype'].isnull()] = rwr_result['Phenotype'].loc[\n",
    "            rwr_result['Phenotype'].isnull()].apply(lambda x: [])\n",
    "        rwr_result = rwr_result.sort_values(by='RWR_score', ascending=False)\n",
    "        \n",
    "        phenotype_rwr_score_dict = {}\n",
    "        for phen in phenotype_list:\n",
    "            phenotype_rwr_score_dict[phen] = 0\n",
    "            \n",
    "        for i in range(len(rwr_result)):\n",
    "            rwr_score = rwr_result['RWR_score'].iloc[i]\n",
    "            if rwr_result['Phenotype'].iloc[i]:\n",
    "                for phen in rwr_result['Phenotype'].iloc[i]:\n",
    "                    phenotype_rwr_score_dict[phen] += rwr_score\n",
    "\n",
    "        key_list=list(phenotype_rwr_score_dict.keys())\n",
    "        for i in key_list:\n",
    "            if i not in output_dict:\n",
    "                output_dict[i]=list([phenotype_rwr_score_dict[i]])\n",
    "            else:\n",
    "                output_dict[i].append(phenotype_rwr_score_dict[i])\n",
    "\n",
    "        with open(\"Results/Direct_GOBP/Compound group_{}/output_dict.pickle\".format(number),\"wb\") as f:\n",
    "            pickle.dump(output_dict,f)\n",
    "    print(\"Completed 1,000 random RWR iterations\")\n",
    "    \n",
    "    temp2=list(output_dict.keys())\n",
    "    for i in temp2:\n",
    "        if np.isnan(output_dict[i][0])==True:\n",
    "            output_dict.pop(i)\n",
    "\n",
    "    inferred_phenotype3 = pd.DataFrame(data=[pair for pair in zip(list(output_dict.keys()),\n",
    "                                                                 list(output_dict.values()))],\n",
    "                                      columns=['Phenotype', 'Network_score'])\n",
    "    inferred_phenotype3 = inferred_phenotype3.sort_values(by='Network_score', ascending=False)\n",
    "\n",
    "    inferred_phenotype3.to_csv('Results/Direct_GOBP/Compound group_{}/{}_P_value.csv'.format(number,number),index=False, encoding='UTF-8')\n",
    "\n",
    "    P_value_Phenotype=list(output_dict.keys())\n",
    "    P_value_Score=list(output_dict.values())\n",
    "    \n",
    "    #----------------------------------------------------------------z-score  \n",
    "    count=0\n",
    "    z_score_list=[]\n",
    "    outlier_list=[] \n",
    "    P_value_list=[]\n",
    "    rank_number=0\n",
    "    result_phenotype=[]\n",
    "    result_phenotype_score=[]\n",
    "\n",
    "    for i in range(len(P_value_Score)):\n",
    "        Numberlist=P_value_Score[i].copy()\n",
    "        tmp1=P_value_Phenotype[i]\n",
    "        tmp2=Phenotype_score_Phenotype.index(tmp1)\n",
    "        tmp3=Phenotype_score_Score[tmp2] \n",
    "        Numberlist.append(tmp3)\n",
    "        result_phenotype.append(tmp1)\n",
    "        result_phenotype_score.append(tmp3)\n",
    "\n",
    "        mean = calculate_mean(Numberlist)\n",
    "\n",
    "        std_deviation = calculate_standard_deviation(Numberlist)\n",
    "        if std_deviation==0:    \n",
    "            z_score=0\n",
    "        else:\n",
    "            z_score=(tmp3-mean)/std_deviation\n",
    "\n",
    "        z_score_list.append(z_score)\n",
    "        if z_score >=-2.58 and z_score<=2.58:\n",
    "            outlier=1\n",
    "            count=count+1\n",
    "        else:\n",
    "            outlier=0 \n",
    "        outlier_list.append(outlier) \n",
    "\n",
    "        Numberlist.sort(reverse=True)\n",
    "\n",
    "        rank=Numberlist.index(tmp3) \n",
    "        if rank<5:\n",
    "            rank_number=rank_number+1\n",
    "        P_value_list.append(rank)\n",
    "\n",
    "    Phenotype_score = pd.DataFrame({\n",
    "        'Phenotype': result_phenotype,\n",
    "        'Network_score': result_phenotype_score,\n",
    "        'z-score': z_score_list,\n",
    "        'P-value': P_value_list,\n",
    "    })\n",
    "\n",
    "    Phenotype_score.to_csv('Results/Direct_GOBP/Compound group_{}/{}_validation.csv'.format(number,number),index=False, encoding='UTF-8')\n",
    "    \n",
    "    network_scores = Phenotype_score['Network_score']\n",
    "\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    scaled_scores = scaler.fit_transform(network_scores.values.reshape(-1, 1)) \n",
    "\n",
    "    Phenotype_score['scaling_score'] = scaled_scores\n",
    "\n",
    "    def adjust_pvalue(value):\n",
    "        if value == 999 or value == 1000:\n",
    "            return 1\n",
    "        else:\n",
    "            return (value+1) / 1000\n",
    "\n",
    "    Phenotype_score['P-value'] = Phenotype_score['P-value'].apply(adjust_pvalue)\n",
    "\n",
    "\n",
    "    #------------------------------------Merge phenotype scores with UMLS IDs\n",
    "\n",
    "    file_2= pd.read_csv(\"Dataset/UMLSID.csv\")\n",
    "\n",
    "    file_3 = pd.merge(Phenotype_score, file_2[['umlsid', 'phenotype','hpoid']], left_on='Phenotype', right_on='phenotype', how='left')\n",
    "\n",
    "    file_3.drop(columns=['phenotype'], inplace=True)\n",
    "    Phenotype_score=file_3\n",
    "\n",
    "    mapping_df = pd.read_excel('Dataset/phenotype mappingv4.xlsx', engine='openpyxl')\n",
    "\n",
    "    grouped_mapping_df = mapping_df.groupby('UMLSID')['Group'].agg(lambda x: ','.join(x)).reset_index()\n",
    "\n",
    "    final_df = pd.merge(Phenotype_score, grouped_mapping_df, left_on='umlsid', right_on='UMLSID', how='left')\n",
    "\n",
    "    final_df.drop(columns=['UMLSID'], inplace=True)\n",
    "\n",
    "    cols_to_drop = [col for col in final_df.columns if col.startswith(\"Unnamed\")]\n",
    "    final_df = final_df.drop(columns=cols_to_drop)\n",
    "\n",
    "    final_df.to_csv('Results/Direct_GOBP/Compound group_{}/{}_validation_with_scaling.csv'.format(number,number), index=False)\n",
    "    \n",
    "\n",
    "end = time.time()\n",
    "sec = (end - start)\n",
    "result = datetime.timedelta(seconds=sec)\n",
    "print(\"Elapsed time : \",result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c6b7a5-959f-4085-bee7-a2dbaabb385c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jy1",
   "language": "python",
   "name": "jy1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
